{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# intermediate_SARC\n",
    "This notebook takes our custom XED binary datas_et and trains an intermediate model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Platform Check\n",
    "Ensure we're on an ARM environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're Armed: macOS-13.0-arm64-i386-64bit\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "\n",
    "if platform.platform() == 'macOS-13.0-arm64-i386-64bit':\n",
    "    print(f\"We're Armed: {platform.platform()}\")\n",
    "else:\n",
    "    print(f\"WARNING! NOT ARMED: {platform.platform()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, update working directory to parent so that we may use our custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jarradjinx/Library/Mobile Documents/com~apple~CloudDocs/EDU_leeds/LD_research/LD_ITESD'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    " \n",
    "os.chdir('..')\n",
    "os.getcwd( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x29481afb0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import params\n",
    "from utils import *\n",
    "from trainer import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "from datasets import load_from_disk, load_metric\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "# from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# suppress model warning\n",
    "from transformers import logging\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "# set logging level\n",
    "import logging\n",
    "logging.basicConfig(level='INFO')\n",
    "\n",
    "# set general seeds\n",
    "set_seeds(1)\n",
    "\n",
    "# set dataloader generator seed\n",
    "g = torch.Generator()\n",
    "g.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SARC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"../data/inter_HellaSwag/hellaswag.hf\"\n",
    "hellaswag_datasets = load_from_disk(\"data/inter_HellaSwag/hellaswag.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ind', 'activity_label', 'ctx_a', 'ctx_b', 'ctx', 'endings', 'source_id', 'split', 'split_type', 'label', 'ending0', 'ending1', 'ending2', 'ending3'],\n",
       "        num_rows: 39905\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['ind', 'activity_label', 'ctx_a', 'ctx_b', 'ctx', 'endings', 'source_id', 'split', 'split_type', 'label', 'ending0', 'ending1', 'ending2', 'ending3'],\n",
       "        num_rows: 10042\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hellaswag_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: A group of athletes row on canoes during a race in between buoys on a waterway.\n",
      "  A - the men pass over a wooden structure in the river.\n",
      "  B - the men paddle while crashing through endless waves in the river.\n",
      "  C - the men cross the final numbered buoys and glide while slowing down after the race.\n",
      "  D - the men go over large cliffs into a lagoon.\n",
      "\n",
      "Ground truth: option C\n"
     ]
    }
   ],
   "source": [
    "def show_one(example):\n",
    "    print(f\"Context: {example['ctx_a']}\")\n",
    "    print(f\"  A - {example['ctx_b']} {example['ending0']}\")\n",
    "    print(f\"  B - {example['ctx_b']} {example['ending1']}\")\n",
    "    print(f\"  C - {example['ctx_b']} {example['ending2']}\")\n",
    "    print(f\"  D - {example['ctx_b']} {example['ending3']}\")\n",
    "    print(f\"\\nGround truth: option {['A', 'B', 'C', 'D'][example['label']]}\")\n",
    "\n",
    "show_one(hellaswag_datasets[\"train\"][250])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\", use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ending_names = [\"ending0\", \"ending1\", \"ending2\", \"ending3\"]\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # Repeat each first sentence four times to go with the four possibilities of second sentences.\n",
    "    first_sentences = [[context] * 4 for context in examples[\"ctx_a\"]]\n",
    "    # Grab all second sentences possible for each context.\n",
    "    question_headers = examples[\"ctx_b\"]\n",
    "    second_sentences = [[f\"{header} {examples[end][i]}\" for end in ending_names] for i, header in enumerate(question_headers)]\n",
    "    \n",
    "    # Flatten everything\n",
    "    first_sentences = sum(first_sentences, [])\n",
    "    second_sentences = sum(second_sentences, [])\n",
    "    \n",
    "    # Tokenize\n",
    "    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True)\n",
    "    # Un-flatten\n",
    "    return {k: [v[i:i+4] for i in range(0, len(v), 4)] for k, v in tokenized_examples.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 4 [40, 55, 44, 39]\n"
     ]
    }
   ],
   "source": [
    "examples = hellaswag_datasets[\"train\"][:5]\n",
    "features = preprocess_function(examples)\n",
    "print(len(features[\"input_ids\"]), len(features[\"input_ids\"][0]), [len(x) for x in features[\"input_ids\"][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>A tray of potatoes is loaded into the oven and removed. A large tray of cake is flipped over and placed on counter.</s></s>a large tray of meat is placed onto a baked potato.</s>',\n",
       " '<s>A tray of potatoes is loaded into the oven and removed. A large tray of cake is flipped over and placed on counter.</s></s>a large tray of meat, ls, and pickles are placed in the oven.</s>',\n",
       " '<s>A tray of potatoes is loaded into the oven and removed. A large tray of cake is flipped over and placed on counter.</s></s>a large tray of meat is poured into a midden.</s>',\n",
       " '<s>A tray of potatoes is loaded into the oven and removed. A large tray of cake is flipped over and placed on counter.</s></s>a large tray of meat is prepared then it is removed from the oven by a helper when done.</s>']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 3\n",
    "[tokenizer.decode(features[\"input_ids\"][idx][i]) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: A tray of potatoes is loaded into the oven and removed. A large tray of cake is flipped over and placed on counter.\n",
      "  A - a large tray of meat is placed onto a baked potato.\n",
      "  B - a large tray of meat , ls, and pickles are placed in the oven.\n",
      "  C - a large tray of meat is poured into a midden.\n",
      "  D - a large tray of meat is prepared then it is removed from the oven by a helper when done.\n",
      "\n",
      "Ground truth: option D\n"
     ]
    }
   ],
   "source": [
    "show_one(hellaswag_datasets[\"train\"][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at data/inter_HellaSwag/hellaswag.hf/train/cache-973c94db277606a3.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at data/inter_HellaSwag/hellaswag.hf/validation/cache-5b518714b86578fd.arrow\n"
     ]
    }
   ],
   "source": [
    "encoded_datasets = hellaswag_datasets.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ind', 'activity_label', 'ctx_a', 'ctx_b', 'ctx', 'endings', 'source_id', 'split', 'split_type', 'label', 'ending0', 'ending1', 'ending2', 'ending3', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 39905\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['ind', 'activity_label', 'ctx_a', 'ctx_b', 'ctx', 'endings', 'source_id', 'split', 'split_type', 'label', 'ending0', 'ending1', 'ending2', 'ending3', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 10042\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download transformers.RobertaForSequenceClassificatio, which is a RoBERTa model with a linear layer for sentence classification (or regression) on top of the pooled output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
    "from transformers import RobertaTokenizer, RobertaForMultipleChoice\n",
    "\n",
    "# Load the RobertaForSequenceClassification model\n",
    "model = RobertaForMultipleChoice.from_pretrained('roberta-base')\n",
    "\n",
    "# from torchinfo import summary\n",
    "# summary(model, input_size=(1, 512), dtypes=['torch.IntTensor'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set model to device, initialize trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    f\"roberta-finetuned-hellaswag-test\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0][\"input_ids\"])\n",
    "        flattened_features = [[{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "        \n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        # Un-flatten\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        # Add back labels\n",
    "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 3,\n",
       "  'input_ids': [[0,\n",
       "    12948,\n",
       "    6,\n",
       "    5,\n",
       "    313,\n",
       "    5789,\n",
       "    81,\n",
       "    5,\n",
       "    1958,\n",
       "    4631,\n",
       "    5,\n",
       "    2931,\n",
       "    9,\n",
       "    10,\n",
       "    512,\n",
       "    6,\n",
       "    8,\n",
       "    10,\n",
       "    693,\n",
       "    2498,\n",
       "    2608,\n",
       "    5418,\n",
       "    14504,\n",
       "    4,\n",
       "    2,\n",
       "    2,\n",
       "    13040,\n",
       "    2156,\n",
       "    5,\n",
       "    313,\n",
       "    3639,\n",
       "    19957,\n",
       "    7,\n",
       "    5,\n",
       "    26689,\n",
       "    8,\n",
       "    2599,\n",
       "    24,\n",
       "    4,\n",
       "    2],\n",
       "   [0,\n",
       "    12948,\n",
       "    6,\n",
       "    5,\n",
       "    313,\n",
       "    5789,\n",
       "    81,\n",
       "    5,\n",
       "    1958,\n",
       "    4631,\n",
       "    5,\n",
       "    2931,\n",
       "    9,\n",
       "    10,\n",
       "    512,\n",
       "    6,\n",
       "    8,\n",
       "    10,\n",
       "    693,\n",
       "    2498,\n",
       "    2608,\n",
       "    5418,\n",
       "    14504,\n",
       "    4,\n",
       "    2,\n",
       "    2,\n",
       "    13040,\n",
       "    2156,\n",
       "    10,\n",
       "    621,\n",
       "    792,\n",
       "    10,\n",
       "    10485,\n",
       "    5258,\n",
       "    6,\n",
       "    150,\n",
       "    80,\n",
       "    604,\n",
       "    3117,\n",
       "    5,\n",
       "    471,\n",
       "    9,\n",
       "    5,\n",
       "    621,\n",
       "    2498,\n",
       "    2608,\n",
       "    5418,\n",
       "    1958,\n",
       "    25,\n",
       "    5,\n",
       "    52,\n",
       "    1972,\n",
       "    27095,\n",
       "    4,\n",
       "    2],\n",
       "   [0,\n",
       "    12948,\n",
       "    6,\n",
       "    5,\n",
       "    313,\n",
       "    5789,\n",
       "    81,\n",
       "    5,\n",
       "    1958,\n",
       "    4631,\n",
       "    5,\n",
       "    2931,\n",
       "    9,\n",
       "    10,\n",
       "    512,\n",
       "    6,\n",
       "    8,\n",
       "    10,\n",
       "    693,\n",
       "    2498,\n",
       "    2608,\n",
       "    5418,\n",
       "    14504,\n",
       "    4,\n",
       "    2,\n",
       "    2,\n",
       "    13040,\n",
       "    2156,\n",
       "    5,\n",
       "    313,\n",
       "    4650,\n",
       "    15,\n",
       "    10,\n",
       "    29224,\n",
       "    13738,\n",
       "    9540,\n",
       "    6,\n",
       "    11269,\n",
       "    16430,\n",
       "    19,\n",
       "    1161,\n",
       "    2577,\n",
       "    4,\n",
       "    2],\n",
       "   [0,\n",
       "    12948,\n",
       "    6,\n",
       "    5,\n",
       "    313,\n",
       "    5789,\n",
       "    81,\n",
       "    5,\n",
       "    1958,\n",
       "    4631,\n",
       "    5,\n",
       "    2931,\n",
       "    9,\n",
       "    10,\n",
       "    512,\n",
       "    6,\n",
       "    8,\n",
       "    10,\n",
       "    693,\n",
       "    2498,\n",
       "    2608,\n",
       "    5418,\n",
       "    14504,\n",
       "    4,\n",
       "    2,\n",
       "    2,\n",
       "    13040,\n",
       "    2156,\n",
       "    5,\n",
       "    313,\n",
       "    1388,\n",
       "    8201,\n",
       "    5,\n",
       "    1958,\n",
       "    15,\n",
       "    39,\n",
       "    512,\n",
       "    4,\n",
       "    2]],\n",
       "  'attention_mask': [[1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1],\n",
       "   [1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1],\n",
       "   [1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1],\n",
       "   [1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1]]},\n",
       " {'label': 3,\n",
       "  'input_ids': [[0,\n",
       "    250,\n",
       "    2182,\n",
       "    8172,\n",
       "    11,\n",
       "    1104,\n",
       "    8284,\n",
       "    924,\n",
       "    10,\n",
       "    17709,\n",
       "    9,\n",
       "    14814,\n",
       "    31592,\n",
       "    11,\n",
       "    10,\n",
       "    739,\n",
       "    4647,\n",
       "    10864,\n",
       "    106,\n",
       "    4,\n",
       "    2,\n",
       "    2,\n",
       "    627,\n",
       "    31592,\n",
       "    5585,\n",
       "    8380,\n",
       "    1423,\n",
       "    1168,\n",
       "    2258,\n",
       "    8,\n",
       "    14814,\n",
       "    18833,\n",
       "    4,\n",
       "    2],\n",
       "   [0,\n",
       "    250,\n",
       "    2182,\n",
       "    8172,\n",
       "    11,\n",
       "    1104,\n",
       "    8284,\n",
       "    924,\n",
       "    10,\n",
       "    17709,\n",
       "    9,\n",
       "    14814,\n",
       "    31592,\n",
       "    11,\n",
       "    10,\n",
       "    739,\n",
       "    4647,\n",
       "    10864,\n",
       "    106,\n",
       "    4,\n",
       "    2,\n",
       "    2,\n",
       "    627,\n",
       "    31592,\n",
       "    32,\n",
       "    172,\n",
       "    38073,\n",
       "    19,\n",
       "    6219,\n",
       "    4696,\n",
       "    4,\n",
       "    2],\n",
       "   [0,\n",
       "    250,\n",
       "    2182,\n",
       "    8172,\n",
       "    11,\n",
       "    1104,\n",
       "    8284,\n",
       "    924,\n",
       "    10,\n",
       "    17709,\n",
       "    9,\n",
       "    14814,\n",
       "    31592,\n",
       "    11,\n",
       "    10,\n",
       "    739,\n",
       "    4647,\n",
       "    10864,\n",
       "    106,\n",
       "    4,\n",
       "    2,\n",
       "    2,\n",
       "    627,\n",
       "    31592,\n",
       "    32,\n",
       "    2325,\n",
       "    11,\n",
       "    10,\n",
       "    7031,\n",
       "    22022,\n",
       "    15,\n",
       "    5,\n",
       "    3231,\n",
       "    4,\n",
       "    2],\n",
       "   [0,\n",
       "    250,\n",
       "    2182,\n",
       "    8172,\n",
       "    11,\n",
       "    1104,\n",
       "    8284,\n",
       "    924,\n",
       "    10,\n",
       "    17709,\n",
       "    9,\n",
       "    14814,\n",
       "    31592,\n",
       "    11,\n",
       "    10,\n",
       "    739,\n",
       "    4647,\n",
       "    10864,\n",
       "    106,\n",
       "    4,\n",
       "    2,\n",
       "    2,\n",
       "    627,\n",
       "    31592,\n",
       "    32,\n",
       "    3820,\n",
       "    19,\n",
       "    375,\n",
       "    4458,\n",
       "    8,\n",
       "    7973,\n",
       "    88,\n",
       "    5,\n",
       "    12941,\n",
       "    4,\n",
       "    2]],\n",
       "  'attention_mask': [[1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1],\n",
       "   [1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1],\n",
       "   [1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1],\n",
       "   [1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1]]},\n",
       " {'label': 3,\n",
       "  'input_ids': [[0,\n",
       "    250,\n",
       "    2182,\n",
       "    8172,\n",
       "    11,\n",
       "    1104,\n",
       "    8284,\n",
       "    924,\n",
       "    10,\n",
       "    17709,\n",
       "    9,\n",
       "    14814,\n",
       "    31592,\n",
       "    11,\n",
       "    10,\n",
       "    739,\n",
       "    4647,\n",
       "    10864,\n",
       "    106,\n",
       "    4,\n",
       "    20,\n",
       "    31592,\n",
       "    32,\n",
       "    3820,\n",
       "    19,\n",
       "    375,\n",
       "    4458,\n",
       "    8,\n",
       "    7973,\n",
       "    88,\n",
       "    5,\n",
       "    12941,\n",
       "    4,\n",
       "    2,\n",
       "    2,\n",
       "    102,\n",
       "    7023,\n",
       "    16,\n",
       "    450,\n",
       "    1375,\n",
       "    15,\n",
       "    10,\n",
       "    792,\n",
       "    8,\n",
       "    3931,\n",
       "    66,\n",
       "    63,\n",
       "    13654,\n",
       "    4,\n",
       "    2],\n",
       "   [0,\n",
       "    250,\n",
       "    2182,\n",
       "    8172,\n",
       "    11,\n",
       "    1104,\n",
       "    8284,\n",
       "    924,\n",
       "    10,\n",
       "    17709,\n",
       "    9,\n",
       "    14814,\n",
       "    31592,\n",
       "    11,\n",
       "    10,\n",
       "    739,\n",
       "    4647,\n",
       "    10864,\n",
       "    106,\n",
       "    4,\n",
       "    20,\n",
       "    31592,\n",
       "    32,\n",
       "    3820,\n",
       "    19,\n",
       "    375,\n",
       "    4458,\n",
       "    8,\n",
       "    7973,\n",
       "    88,\n",
       "    5,\n",
       "    12941,\n",
       "    4,\n",
       "    2,\n",
       "    2,\n",
       "    102,\n",
       "    7023,\n",
       "    2323,\n",
       "    5,\n",
       "    32350,\n",
       "    21629,\n",
       "    35427,\n",
       "    6,\n",
       "    1432,\n",
       "    30,\n",
       "    21406,\n",
       "    39127,\n",
       "    1120,\n",
       "    8,\n",
       "    202,\n",
       "    14166,\n",
       "    2480,\n",
       "    6353,\n",
       "    4,\n",
       "    2],\n",
       "   [0,\n",
       "    250,\n",
       "    2182,\n",
       "    8172,\n",
       "    11,\n",
       "    1104,\n",
       "    8284,\n",
       "    924,\n",
       "    10,\n",
       "    17709,\n",
       "    9,\n",
       "    14814,\n",
       "    31592,\n",
       "    11,\n",
       "    10,\n",
       "    739,\n",
       "    4647,\n",
       "    10864,\n",
       "    106,\n",
       "    4,\n",
       "    20,\n",
       "    31592,\n",
       "    32,\n",
       "    3820,\n",
       "    19,\n",
       "    375,\n",
       "    4458,\n",
       "    8,\n",
       "    7973,\n",
       "    88,\n",
       "    5,\n",
       "    12941,\n",
       "    4,\n",
       "    2,\n",
       "    2,\n",
       "    102,\n",
       "    7023,\n",
       "    4400,\n",
       "    5559,\n",
       "    10,\n",
       "    3989,\n",
       "    88,\n",
       "    5,\n",
       "    1025,\n",
       "    9,\n",
       "    5,\n",
       "    17241,\n",
       "    31592,\n",
       "    4,\n",
       "    2],\n",
       "   [0,\n",
       "    250,\n",
       "    2182,\n",
       "    8172,\n",
       "    11,\n",
       "    1104,\n",
       "    8284,\n",
       "    924,\n",
       "    10,\n",
       "    17709,\n",
       "    9,\n",
       "    14814,\n",
       "    31592,\n",
       "    11,\n",
       "    10,\n",
       "    739,\n",
       "    4647,\n",
       "    10864,\n",
       "    106,\n",
       "    4,\n",
       "    20,\n",
       "    31592,\n",
       "    32,\n",
       "    3820,\n",
       "    19,\n",
       "    375,\n",
       "    4458,\n",
       "    8,\n",
       "    7973,\n",
       "    88,\n",
       "    5,\n",
       "    12941,\n",
       "    4,\n",
       "    2,\n",
       "    2,\n",
       "    102,\n",
       "    7023,\n",
       "    16,\n",
       "    341,\n",
       "    7,\n",
       "    847,\n",
       "    31108,\n",
       "    14216,\n",
       "    14397,\n",
       "    88,\n",
       "    5509,\n",
       "    4,\n",
       "    2]],\n",
       "  'attention_mask': [[1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1],\n",
       "   [1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1],\n",
       "   [1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1],\n",
       "   [1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1]]},\n",
       " {'label': 3,\n",
       "  'input_ids': [[0,\n",
       "    250,\n",
       "    27483,\n",
       "    9,\n",
       "    15042,\n",
       "    16,\n",
       "    7973,\n",
       "    88,\n",
       "    5,\n",
       "    12941,\n",
       "    8,\n",
       "    2928,\n",
       "    4,\n",
       "    83,\n",
       "    739,\n",
       "    27483,\n",
       "    9,\n",
       "    8492,\n",
       "    16,\n",
       "    18626,\n",
       "    81,\n",
       "    8,\n",
       "    2325,\n",
       "    15,\n",
       "    3231,\n",
       "    4,\n",
       "    2,\n",
       "    2,\n",
       "    102,\n",
       "    739,\n",
       "    27483,\n",
       "    9,\n",
       "    4884,\n",
       "    16,\n",
       "    2325,\n",
       "    2500,\n",
       "    10,\n",
       "    17241,\n",
       "    17284,\n",
       "    4,\n",
       "    2],\n",
       "   [0,\n",
       "    250,\n",
       "    27483,\n",
       "    9,\n",
       "    15042,\n",
       "    16,\n",
       "    7973,\n",
       "    88,\n",
       "    5,\n",
       "    12941,\n",
       "    8,\n",
       "    2928,\n",
       "    4,\n",
       "    83,\n",
       "    739,\n",
       "    27483,\n",
       "    9,\n",
       "    8492,\n",
       "    16,\n",
       "    18626,\n",
       "    81,\n",
       "    8,\n",
       "    2325,\n",
       "    15,\n",
       "    3231,\n",
       "    4,\n",
       "    2,\n",
       "    2,\n",
       "    102,\n",
       "    739,\n",
       "    27483,\n",
       "    9,\n",
       "    4884,\n",
       "    2156,\n",
       "    47514,\n",
       "    6,\n",
       "    8,\n",
       "    1339,\n",
       "    1634,\n",
       "    32,\n",
       "    2325,\n",
       "    11,\n",
       "    5,\n",
       "    12941,\n",
       "    4,\n",
       "    2],\n",
       "   [0,\n",
       "    250,\n",
       "    27483,\n",
       "    9,\n",
       "    15042,\n",
       "    16,\n",
       "    7973,\n",
       "    88,\n",
       "    5,\n",
       "    12941,\n",
       "    8,\n",
       "    2928,\n",
       "    4,\n",
       "    83,\n",
       "    739,\n",
       "    27483,\n",
       "    9,\n",
       "    8492,\n",
       "    16,\n",
       "    18626,\n",
       "    81,\n",
       "    8,\n",
       "    2325,\n",
       "    15,\n",
       "    3231,\n",
       "    4,\n",
       "    2,\n",
       "    2,\n",
       "    102,\n",
       "    739,\n",
       "    27483,\n",
       "    9,\n",
       "    4884,\n",
       "    16,\n",
       "    13414,\n",
       "    88,\n",
       "    10,\n",
       "    475,\n",
       "    41686,\n",
       "    4,\n",
       "    2],\n",
       "   [0,\n",
       "    250,\n",
       "    27483,\n",
       "    9,\n",
       "    15042,\n",
       "    16,\n",
       "    7973,\n",
       "    88,\n",
       "    5,\n",
       "    12941,\n",
       "    8,\n",
       "    2928,\n",
       "    4,\n",
       "    83,\n",
       "    739,\n",
       "    27483,\n",
       "    9,\n",
       "    8492,\n",
       "    16,\n",
       "    18626,\n",
       "    81,\n",
       "    8,\n",
       "    2325,\n",
       "    15,\n",
       "    3231,\n",
       "    4,\n",
       "    2,\n",
       "    2,\n",
       "    102,\n",
       "    739,\n",
       "    27483,\n",
       "    9,\n",
       "    4884,\n",
       "    16,\n",
       "    2460,\n",
       "    172,\n",
       "    24,\n",
       "    16,\n",
       "    2928,\n",
       "    31,\n",
       "    5,\n",
       "    12941,\n",
       "    30,\n",
       "    10,\n",
       "    39776,\n",
       "    77,\n",
       "    626,\n",
       "    4,\n",
       "    2]],\n",
       "  'attention_mask': [[1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1],\n",
       "   [1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1],\n",
       "   [1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1],\n",
       "   [1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1]]},\n",
       " {'label': 2,\n",
       "  'input_ids': [[0,\n",
       "    133,\n",
       "    313,\n",
       "    11,\n",
       "    5,\n",
       "    1312,\n",
       "    16,\n",
       "    16987,\n",
       "    10,\n",
       "    25124,\n",
       "    14143,\n",
       "    15,\n",
       "    5,\n",
       "    621,\n",
       "    2498,\n",
       "    5,\n",
       "    2440,\n",
       "    6399,\n",
       "    4,\n",
       "    2,\n",
       "    2,\n",
       "    627,\n",
       "    313,\n",
       "    11,\n",
       "    5,\n",
       "    2440,\n",
       "    6399,\n",
       "    16,\n",
       "    2934,\n",
       "    15,\n",
       "    5,\n",
       "    36499,\n",
       "    3931,\n",
       "    5,\n",
       "    2549,\n",
       "    9,\n",
       "    5,\n",
       "    621,\n",
       "    2498,\n",
       "    5,\n",
       "    2440,\n",
       "    6399,\n",
       "    4,\n",
       "    2],\n",
       "   [0,\n",
       "    133,\n",
       "    313,\n",
       "    11,\n",
       "    5,\n",
       "    1312,\n",
       "    16,\n",
       "    16987,\n",
       "    10,\n",
       "    25124,\n",
       "    14143,\n",
       "    15,\n",
       "    5,\n",
       "    621,\n",
       "    2498,\n",
       "    5,\n",
       "    2440,\n",
       "    6399,\n",
       "    4,\n",
       "    2,\n",
       "    2,\n",
       "    627,\n",
       "    313,\n",
       "    11,\n",
       "    5,\n",
       "    2440,\n",
       "    6399,\n",
       "    16,\n",
       "    608,\n",
       "    5,\n",
       "    25124,\n",
       "    14143,\n",
       "    19,\n",
       "    39,\n",
       "    865,\n",
       "    8,\n",
       "    5,\n",
       "    36196,\n",
       "    4862,\n",
       "    857,\n",
       "    4,\n",
       "    2],\n",
       "   [0,\n",
       "    133,\n",
       "    313,\n",
       "    11,\n",
       "    5,\n",
       "    1312,\n",
       "    16,\n",
       "    16987,\n",
       "    10,\n",
       "    25124,\n",
       "    14143,\n",
       "    15,\n",
       "    5,\n",
       "    621,\n",
       "    2498,\n",
       "    5,\n",
       "    2440,\n",
       "    6399,\n",
       "    4,\n",
       "    2,\n",
       "    2,\n",
       "    627,\n",
       "    313,\n",
       "    11,\n",
       "    5,\n",
       "    2440,\n",
       "    6399,\n",
       "    6476,\n",
       "    15,\n",
       "    5,\n",
       "    3428,\n",
       "    220,\n",
       "    7,\n",
       "    5,\n",
       "    12045,\n",
       "    4,\n",
       "    2],\n",
       "   [0,\n",
       "    133,\n",
       "    313,\n",
       "    11,\n",
       "    5,\n",
       "    1312,\n",
       "    16,\n",
       "    16987,\n",
       "    10,\n",
       "    25124,\n",
       "    14143,\n",
       "    15,\n",
       "    5,\n",
       "    621,\n",
       "    2498,\n",
       "    5,\n",
       "    2440,\n",
       "    6399,\n",
       "    4,\n",
       "    2,\n",
       "    2,\n",
       "    627,\n",
       "    313,\n",
       "    11,\n",
       "    5,\n",
       "    2440,\n",
       "    6399,\n",
       "    16,\n",
       "    145,\n",
       "    2343,\n",
       "    2295,\n",
       "    7,\n",
       "    2295,\n",
       "    4,\n",
       "    2]],\n",
       "  'attention_mask': [[1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1],\n",
       "   [1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1],\n",
       "   [1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1],\n",
       "   [1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1]]}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accepted_keys = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "features = [{k: v for k, v in encoded_datasets[\"train\"][i].items() if k in accepted_keys} for i in range(5)]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in features:\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [feature.pop(\"label\") for feature in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "\n",
      "[[{'input_ids': [0, 12948, 6, 5, 313, 5789, 81, 5, 1958, 4631, 5, 2931, 9, 10, 512, 6, 8, 10, 693, 2498, 2608, 5418, 14504, 4, 2, 2, 13040, 2156, 5, 313, 3639, 19957, 7, 5, 26689, 8, 2599, 24, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'input_ids': [0, 12948, 6, 5, 313, 5789, 81, 5, 1958, 4631, 5, 2931, 9, 10, 512, 6, 8, 10, 693, 2498, 2608, 5418, 14504, 4, 2, 2, 13040, 2156, 10, 621, 792, 10, 10485, 5258, 6, 150, 80, 604, 3117, 5, 471, 9, 5, 621, 2498, 2608, 5418, 1958, 25, 5, 52, 1972, 27095, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'input_ids': [0, 12948, 6, 5, 313, 5789, 81, 5, 1958, 4631, 5, 2931, 9, 10, 512, 6, 8, 10, 693, 2498, 2608, 5418, 14504, 4, 2, 2, 13040, 2156, 5, 313, 4650, 15, 10, 29224, 13738, 9540, 6, 11269, 16430, 19, 1161, 2577, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'input_ids': [0, 12948, 6, 5, 313, 5789, 81, 5, 1958, 4631, 5, 2931, 9, 10, 512, 6, 8, 10, 693, 2498, 2608, 5418, 14504, 4, 2, 2, 13040, 2156, 5, 313, 1388, 8201, 5, 1958, 15, 39, 512, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}], [{'input_ids': [0, 250, 2182, 8172, 11, 1104, 8284, 924, 10, 17709, 9, 14814, 31592, 11, 10, 739, 4647, 10864, 106, 4, 2, 2, 627, 31592, 5585, 8380, 1423, 1168, 2258, 8, 14814, 18833, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'input_ids': [0, 250, 2182, 8172, 11, 1104, 8284, 924, 10, 17709, 9, 14814, 31592, 11, 10, 739, 4647, 10864, 106, 4, 2, 2, 627, 31592, 32, 172, 38073, 19, 6219, 4696, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'input_ids': [0, 250, 2182, 8172, 11, 1104, 8284, 924, 10, 17709, 9, 14814, 31592, 11, 10, 739, 4647, 10864, 106, 4, 2, 2, 627, 31592, 32, 2325, 11, 10, 7031, 22022, 15, 5, 3231, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'input_ids': [0, 250, 2182, 8172, 11, 1104, 8284, 924, 10, 17709, 9, 14814, 31592, 11, 10, 739, 4647, 10864, 106, 4, 2, 2, 627, 31592, 32, 3820, 19, 375, 4458, 8, 7973, 88, 5, 12941, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}], [{'input_ids': [0, 250, 2182, 8172, 11, 1104, 8284, 924, 10, 17709, 9, 14814, 31592, 11, 10, 739, 4647, 10864, 106, 4, 20, 31592, 32, 3820, 19, 375, 4458, 8, 7973, 88, 5, 12941, 4, 2, 2, 102, 7023, 16, 450, 1375, 15, 10, 792, 8, 3931, 66, 63, 13654, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'input_ids': [0, 250, 2182, 8172, 11, 1104, 8284, 924, 10, 17709, 9, 14814, 31592, 11, 10, 739, 4647, 10864, 106, 4, 20, 31592, 32, 3820, 19, 375, 4458, 8, 7973, 88, 5, 12941, 4, 2, 2, 102, 7023, 2323, 5, 32350, 21629, 35427, 6, 1432, 30, 21406, 39127, 1120, 8, 202, 14166, 2480, 6353, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'input_ids': [0, 250, 2182, 8172, 11, 1104, 8284, 924, 10, 17709, 9, 14814, 31592, 11, 10, 739, 4647, 10864, 106, 4, 20, 31592, 32, 3820, 19, 375, 4458, 8, 7973, 88, 5, 12941, 4, 2, 2, 102, 7023, 4400, 5559, 10, 3989, 88, 5, 1025, 9, 5, 17241, 31592, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'input_ids': [0, 250, 2182, 8172, 11, 1104, 8284, 924, 10, 17709, 9, 14814, 31592, 11, 10, 739, 4647, 10864, 106, 4, 20, 31592, 32, 3820, 19, 375, 4458, 8, 7973, 88, 5, 12941, 4, 2, 2, 102, 7023, 16, 341, 7, 847, 31108, 14216, 14397, 88, 5509, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}], [{'input_ids': [0, 250, 27483, 9, 15042, 16, 7973, 88, 5, 12941, 8, 2928, 4, 83, 739, 27483, 9, 8492, 16, 18626, 81, 8, 2325, 15, 3231, 4, 2, 2, 102, 739, 27483, 9, 4884, 16, 2325, 2500, 10, 17241, 17284, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'input_ids': [0, 250, 27483, 9, 15042, 16, 7973, 88, 5, 12941, 8, 2928, 4, 83, 739, 27483, 9, 8492, 16, 18626, 81, 8, 2325, 15, 3231, 4, 2, 2, 102, 739, 27483, 9, 4884, 2156, 47514, 6, 8, 1339, 1634, 32, 2325, 11, 5, 12941, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'input_ids': [0, 250, 27483, 9, 15042, 16, 7973, 88, 5, 12941, 8, 2928, 4, 83, 739, 27483, 9, 8492, 16, 18626, 81, 8, 2325, 15, 3231, 4, 2, 2, 102, 739, 27483, 9, 4884, 16, 13414, 88, 10, 475, 41686, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'input_ids': [0, 250, 27483, 9, 15042, 16, 7973, 88, 5, 12941, 8, 2928, 4, 83, 739, 27483, 9, 8492, 16, 18626, 81, 8, 2325, 15, 3231, 4, 2, 2, 102, 739, 27483, 9, 4884, 16, 2460, 172, 24, 16, 2928, 31, 5, 12941, 30, 10, 39776, 77, 626, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}], [{'input_ids': [0, 133, 313, 11, 5, 1312, 16, 16987, 10, 25124, 14143, 15, 5, 621, 2498, 5, 2440, 6399, 4, 2, 2, 627, 313, 11, 5, 2440, 6399, 16, 2934, 15, 5, 36499, 3931, 5, 2549, 9, 5, 621, 2498, 5, 2440, 6399, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'input_ids': [0, 133, 313, 11, 5, 1312, 16, 16987, 10, 25124, 14143, 15, 5, 621, 2498, 5, 2440, 6399, 4, 2, 2, 627, 313, 11, 5, 2440, 6399, 16, 608, 5, 25124, 14143, 19, 39, 865, 8, 5, 36196, 4862, 857, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'input_ids': [0, 133, 313, 11, 5, 1312, 16, 16987, 10, 25124, 14143, 15, 5, 621, 2498, 5, 2440, 6399, 4, 2, 2, 627, 313, 11, 5, 2440, 6399, 6476, 15, 5, 3428, 220, 7, 5, 12045, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'input_ids': [0, 133, 313, 11, 5, 1312, 16, 16987, 10, 25124, 14143, 15, 5, 621, 2498, 5, 2440, 6399, 4, 2, 2, 627, 313, 11, 5, 2440, 6399, 16, 145, 2343, 2295, 7, 2295, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}]]\n",
      "\n",
      "[{'input_ids': [0, 12948, 6, 5, 313, 5789, 81, 5, 1958, 4631, 5, 2931, 9, 10, 512, 6, 8, 10, 693, 2498, 2608, 5418, 14504, 4, 2, 2, 13040, 2156, 5, 313, 3639, 19957, 7, 5, 26689, 8, 2599, 24, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'input_ids': [0, 12948, 6, 5, 313, 5789, 81, 5, 1958, 4631, 5, 2931, 9, 10, 512, 6, 8, 10, 693, 2498, 2608, 5418, 14504, 4, 2, 2, 13040, 2156, 10, 621, 792, 10, 10485, 5258, 6, 150, 80, 604, 3117, 5, 471, 9, 5, 621, 2498, 2608, 5418, 1958, 25, 5, 52, 1972, 27095, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'input_ids': [0, 12948, 6, 5, 313, 5789, 81, 5, 1958, 4631, 5, 2931, 9, 10, 512, 6, 8, 10, 693, 2498, 2608, 5418, 14504, 4, 2, 2, 13040, 2156, 5, 313, 4650, 15, 10, 29224, 13738, 9540, 6, 11269, 16430, 19, 1161, 2577, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'input_ids': [0, 12948, 6, 5, 313, 5789, 81, 5, 1958, 4631, 5, 2931, 9, 10, 512, 6, 8, 10, 693, 2498, 2608, 5418, 14504, 4, 2, 2, 13040, 2156, 5, 313, 1388, 8201, 5, 1958, 15, 39, 512, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'input_ids': [0, 250, 2182, 8172, 11, 1104, 8284, 924, 10, 17709, 9, 14814, 31592, 11, 10, 739, 4647, 10864, 106, 4, 2, 2, 627, 31592, 5585, 8380, 1423, 1168, 2258, 8, 14814, 18833, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'input_ids': [0, 250, 2182, 8172, 11, 1104, 8284, 924, 10, 17709, 9, 14814, 31592, 11, 10, 739, 4647, 10864, 106, 4, 2, 2, 627, 31592, 32, 172, 38073, 19, 6219, 4696, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'input_ids': [0, 250, 2182, 8172, 11, 1104, 8284, 924, 10, 17709, 9, 14814, 31592, 11, 10, 739, 4647, 10864, 106, 4, 2, 2, 627, 31592, 32, 2325, 11, 10, 7031, 22022, 15, 5, 3231, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'input_ids': [0, 250, 2182, 8172, 11, 1104, 8284, 924, 10, 17709, 9, 14814, 31592, 11, 10, 739, 4647, 10864, 106, 4, 2, 2, 627, 31592, 32, 3820, 19, 375, 4458, 8, 7973, 88, 5, 12941, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'input_ids': [0, 250, 2182, 8172, 11, 1104, 8284, 924, 10, 17709, 9, 14814, 31592, 11, 10, 739, 4647, 10864, 106, 4, 20, 31592, 32, 3820, 19, 375, 4458, 8, 7973, 88, 5, 12941, 4, 2, 2, 102, 7023, 16, 450, 1375, 15, 10, 792, 8, 3931, 66, 63, 13654, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'input_ids': [0, 250, 2182, 8172, 11, 1104, 8284, 924, 10, 17709, 9, 14814, 31592, 11, 10, 739, 4647, 10864, 106, 4, 20, 31592, 32, 3820, 19, 375, 4458, 8, 7973, 88, 5, 12941, 4, 2, 2, 102, 7023, 2323, 5, 32350, 21629, 35427, 6, 1432, 30, 21406, 39127, 1120, 8, 202, 14166, 2480, 6353, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'input_ids': [0, 250, 2182, 8172, 11, 1104, 8284, 924, 10, 17709, 9, 14814, 31592, 11, 10, 739, 4647, 10864, 106, 4, 20, 31592, 32, 3820, 19, 375, 4458, 8, 7973, 88, 5, 12941, 4, 2, 2, 102, 7023, 4400, 5559, 10, 3989, 88, 5, 1025, 9, 5, 17241, 31592, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'input_ids': [0, 250, 2182, 8172, 11, 1104, 8284, 924, 10, 17709, 9, 14814, 31592, 11, 10, 739, 4647, 10864, 106, 4, 20, 31592, 32, 3820, 19, 375, 4458, 8, 7973, 88, 5, 12941, 4, 2, 2, 102, 7023, 16, 341, 7, 847, 31108, 14216, 14397, 88, 5509, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'input_ids': [0, 250, 27483, 9, 15042, 16, 7973, 88, 5, 12941, 8, 2928, 4, 83, 739, 27483, 9, 8492, 16, 18626, 81, 8, 2325, 15, 3231, 4, 2, 2, 102, 739, 27483, 9, 4884, 16, 2325, 2500, 10, 17241, 17284, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'input_ids': [0, 250, 27483, 9, 15042, 16, 7973, 88, 5, 12941, 8, 2928, 4, 83, 739, 27483, 9, 8492, 16, 18626, 81, 8, 2325, 15, 3231, 4, 2, 2, 102, 739, 27483, 9, 4884, 2156, 47514, 6, 8, 1339, 1634, 32, 2325, 11, 5, 12941, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'input_ids': [0, 250, 27483, 9, 15042, 16, 7973, 88, 5, 12941, 8, 2928, 4, 83, 739, 27483, 9, 8492, 16, 18626, 81, 8, 2325, 15, 3231, 4, 2, 2, 102, 739, 27483, 9, 4884, 16, 13414, 88, 10, 475, 41686, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'input_ids': [0, 250, 27483, 9, 15042, 16, 7973, 88, 5, 12941, 8, 2928, 4, 83, 739, 27483, 9, 8492, 16, 18626, 81, 8, 2325, 15, 3231, 4, 2, 2, 102, 739, 27483, 9, 4884, 16, 2460, 172, 24, 16, 2928, 31, 5, 12941, 30, 10, 39776, 77, 626, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'input_ids': [0, 133, 313, 11, 5, 1312, 16, 16987, 10, 25124, 14143, 15, 5, 621, 2498, 5, 2440, 6399, 4, 2, 2, 627, 313, 11, 5, 2440, 6399, 16, 2934, 15, 5, 36499, 3931, 5, 2549, 9, 5, 621, 2498, 5, 2440, 6399, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'input_ids': [0, 133, 313, 11, 5, 1312, 16, 16987, 10, 25124, 14143, 15, 5, 621, 2498, 5, 2440, 6399, 4, 2, 2, 627, 313, 11, 5, 2440, 6399, 16, 608, 5, 25124, 14143, 19, 39, 865, 8, 5, 36196, 4862, 857, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'input_ids': [0, 133, 313, 11, 5, 1312, 16, 16987, 10, 25124, 14143, 15, 5, 621, 2498, 5, 2440, 6399, 4, 2, 2, 627, 313, 11, 5, 2440, 6399, 6476, 15, 5, 3428, 220, 7, 5, 12045, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'input_ids': [0, 133, 313, 11, 5, 1312, 16, 16987, 10, 25124, 14143, 15, 5, 621, 2498, 5, 2440, 6399, 4, 2, 2, 627, 313, 11, 5, 2440, 6399, 16, 145, 2343, 2295, 7, 2295, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}]\n"
     ]
    }
   ],
   "source": [
    "num_choices = len(features[0][\"input_ids\"])\n",
    "print(num_choices)\n",
    "flattened_features = [[{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features]\n",
    "print('')\n",
    "print(flattened_features)\n",
    "flattened_features = sum(flattened_features, [])\n",
    "print('')\n",
    "print(flattened_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_2 = tokenizer.pad(\n",
    "    flattened_features,\n",
    "    max_length = params.max_length,\n",
    "    padding='max_length',\n",
    "    return_tensors=\"pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    0, 12948,     6,  ...,     1,     1,     1],\n",
      "        [    0, 12948,     6,  ...,     1,     1,     1],\n",
      "        [    0, 12948,     6,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [    0,   133,   313,  ...,     1,     1,     1],\n",
      "        [    0,   133,   313,  ...,     1,     1,     1],\n",
      "        [    0,   133,   313,  ...,     1,     1,     1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "# OK SO THE GOAL IS TO 1PAD THE INPUTS AND ZERO PAD THE ATTENTION MASKS\n",
    "print(batch_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = DataCollatorForMultipleChoice(tokenizer)(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['attention_mask'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[tokenizer.decode(batch[\"input_ids\"][0][i].tolist()) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels are 0 indexed, so this is the last label\n",
    "batch[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_predictions):\n",
    "    predictions, label_ids = eval_predictions\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (preds == label_ids).astype(np.float32).mean().item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_datasets[\"train\"],\n",
    "    eval_dataset=encoded_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(params.device)\n",
    "print(f\"Trained Dataset: {dataset_path}\")\n",
    "print(f\"Device: {params.device}\")\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=params.learning_rate) #roberta\n",
    "\n",
    "trainer = Trainer(model=model,\n",
    "                  device=params.device,\n",
    "                  tokenizer=params.tokenizer,\n",
    "                  train_dataloader=train_dataloader,\n",
    "                  validation_dataloader=validation_dataloader,\n",
    "                  epochs=params.epochs,\n",
    "                  optimizer=optimizer,\n",
    "                  val_loss_fn=params.val_loss_fn,\n",
    "                  num_labels=params.num_labels,\n",
    "                  notify=params.notify,\n",
    "                  phone_number=params.phone_number,\n",
    "                  save_dir=params.save_dir,\n",
    "                  model_name=params.model_name, \n",
    "                  save_freq=params.save_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model to our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('eda_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44cd29fc0e411fd9962b44395a3726d6ca1c09530fabf57436a3af7bf7cec47b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
