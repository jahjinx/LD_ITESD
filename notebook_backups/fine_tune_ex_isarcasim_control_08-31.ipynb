{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Platform Check\n",
    "Ensure we're on an ARM environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'macOS-13.0-arm64-i386-64bit'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import platform\n",
    "\n",
    "if platform.platform() == 'macOS-13.0-arm64-i386-64bit':\n",
    "    print(f\"We're Armed: {platform.platform()}\")\n",
    "else:\n",
    "    print(f\"WARNING! NOT ARMED: {platform.platform()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings & Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, update working directory to parent so that we may use our custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    " \n",
    "os.chdir('..')\n",
    "os.getcwd( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import params\n",
    "from trainer import *\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "from transformers import set_seed\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "# from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# suppress model warning\n",
    "from transformers import logging\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level='INFO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "set_seed(1)\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SARC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'data/SARC/train-balanced-sarcasm.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "df = df.rename(columns={'comment': 'text'})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['text'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_amounts = {0:10000, 1:10000}\n",
    "\n",
    "df = (\n",
    "    df.groupby('label').apply(lambda g: g.sample(\n",
    "        # lookup number of samples to take\n",
    "        n=sample_amounts[g.name],\n",
    "        # enable replacement if len is less than number of samples expected\n",
    "        replace=len(g) < sample_amounts[g.name]  \n",
    "    ))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"text\", \"label\"]].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SemEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'data/target_semEval2022_en/iSarcasmEval-main/train/train.en.prepped-oversampled.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "df = df.rename(columns={'tweet': 'text'})\n",
    "df = df.rename(columns={'sarcastic': 'label'})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_amounts = {0: 300, 1:300}\n",
    "\n",
    "df = (\n",
    "    df.groupby('label').apply(lambda g: g.sample(\n",
    "        # lookup number of samples to take\n",
    "        n=sample_amounts[g.name],\n",
    "        # enable replacement if len is less than number of samples expected\n",
    "        replace=len(g) < sample_amounts[g.name]  \n",
    "    ))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Text & Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df.text.values\n",
    "labels = df.label.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_id = []\n",
    "attention_masks = []\n",
    "\n",
    "# TODO change max_length\n",
    "def preprocessing(input_text, tokenizer):\n",
    "  '''\n",
    "  Returns <class transformers.tokenization_utils_base.BatchEncoding> with the following fields:\n",
    "    - input_ids: list of token ids\n",
    "    - token_type_ids: list of token type ids\n",
    "    - attention_mask: list of indices (0,1) specifying which tokens should considered by the model (return_attention_mask = True).\n",
    "  '''\n",
    "  return tokenizer.encode_plus(\n",
    "                        input_text,\n",
    "                        add_special_tokens = True,\n",
    "                        max_length = params.max_length,\n",
    "                        padding='max_length',\n",
    "                        truncation=True,\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt'\n",
    "                   )\n",
    "\n",
    "\n",
    "for sample in text:\n",
    "  encoding_dict = preprocessing(sample, params.tokenizer)\n",
    "  token_id.append(encoding_dict['input_ids']) \n",
    "  attention_masks.append(encoding_dict['attention_mask'])\n",
    "\n",
    "\n",
    "token_id = torch.cat(token_id, dim = 0)\n",
    "attention_masks = torch.cat(attention_masks, dim = 0)\n",
    "labels = torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe the token IDs for a text sample and recognize the presence of the special tokens [CLS] and [SEP], as well as the padding [PAD] up to the desired max_length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_id[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Split\n",
    "We split the dataset into train (80%) and validation (20%) sets, and wrap them around a torch.utils.data.DataLoader object. With its intuitive syntax, DataLoader provides an iterable over the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ratio = 0.2\n",
    "\n",
    "# Indices of the train and validation splits stratified by labels\n",
    "train_idx, val_idx = train_test_split(\n",
    "    np.arange(len(labels)),\n",
    "    test_size = val_ratio,\n",
    "    shuffle = True,\n",
    "    stratify = labels,\n",
    "    random_state=1)\n",
    "\n",
    "# Train and validation sets\n",
    "train_set = TensorDataset(token_id[train_idx], \n",
    "                          attention_masks[train_idx], \n",
    "                          labels[train_idx])\n",
    "\n",
    "val_set = TensorDataset(token_id[val_idx], \n",
    "                        attention_masks[val_idx], \n",
    "                        labels[val_idx])\n",
    "\n",
    "# Prepare DataLoader\n",
    "train_dataloader = DataLoader(\n",
    "            train_set,\n",
    "            sampler = RandomSampler(train_set),\n",
    "            batch_size = params.batch_size,\n",
    "            worker_init_fn=seed_worker,\n",
    "            generator=g,\n",
    "        )\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "            val_set,\n",
    "            sampler = SequentialSampler(val_set),\n",
    "            batch_size = params.batch_size,\n",
    "            worker_init_fn=seed_worker,\n",
    "            generator=g,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "It is time for the fine-tuning task:\n",
    "\n",
    "Select hyperparameters based on the recommendations from the BERT paper¹:\n",
    "The optimal hyperparameter values are task-specific, but we found the following range of possible values to work well across all tasks:\n",
    "\n",
    "- Batch size: 16, 32\n",
    "\n",
    "- Learning rate (Adam): 5e-5, 3e-5, 2e-5\n",
    "\n",
    "- Number of epochs: 2, 3, 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download transformers.BertForSequenceClassification¹¹, which is a BERT model with a linear layer for sentence classification (or regression) on top of the pooled output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the BertForSequenceClassification model\n",
    "# model = BertForSequenceClassification.from_pretrained(\n",
    "#     'bert-base-uncased',\n",
    "#     num_labels = 2,\n",
    "#     output_attentions = False,\n",
    "#     output_hidden_states = False,\n",
    "# )\n",
    "\n",
    "# Load the RobertaForSequenceClassification model\n",
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    'roberta-base',\n",
    "    num_labels = params.num_labels,\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False,\n",
    ")\n",
    "\n",
    "from torchinfo import summary\n",
    "summary(model, input_size=(1, 512), dtypes=['torch.IntTensor'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: it is preferable to run this notebook in the presence of GPU. In order to execute it on CPU, we should comment model.cuda() in the above snippet to avoid a runtime error.\n",
    "\n",
    "Perform the training procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(params.device)\n",
    "print(f\"Trained Dataset: {dataset_path}\")\n",
    "print(f\"Device: {params.device}\")\n",
    "\n",
    "optimizer    = torch.optim.Adam(params=model.parameters(), lr=1e-05) #roberta\n",
    "\n",
    "trainer = Trainer(model=model,\n",
    "                  device=params.device,\n",
    "                  tokenizer=params.tokenizer,\n",
    "                  train_dataloader=train_dataloader,\n",
    "                  validation_dataloader=validation_dataloader,\n",
    "                  epochs=params.epochs,\n",
    "                  optimizer=optimizer,\n",
    "                  val_loss_fn=params.val_loss_fn,\n",
    "                  notify=params.notify,\n",
    "                  phone_number=params.phone_number,\n",
    "                  save_dir=params.save_dir,\n",
    "                  model_name=params.model_name, \n",
    "                  save_freq=params.save_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "model.to(device)\n",
    "\n",
    "print(f\"Trained Dataset: {dataset_path}\")\n",
    "\n",
    "# Recommended learning rates (Adam): 5e-5, 3e-5, 2e-5. See: https://arxiv.org/pdf/1810.04805.pdf\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), \n",
    "#                               lr = 5e-5,\n",
    "#                             #   lr = .01,\n",
    "#                               eps = 1e-08\n",
    "#                               )\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-05) #roberta\n",
    "\n",
    "# Recommended number of epochs: 2, 3, 4. See: https://arxiv.org/pdf/1810.04805.pdf\n",
    "epochs = 10\n",
    "notify = False\n",
    "\n",
    "# loss function for validation loop\n",
    "val_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# def compute_loss(logits, inputs, return_outputs=False):\n",
    "#     logits =logits.to('mps')\n",
    "#     labels = inputs.to('mps')\n",
    "#     # compute custom loss (suppose one has 3 labels with different weights)\n",
    "#     loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([0.6667, 1.9994])).to('mps')\n",
    "#     loss = loss_fct(logits.view(-1, 2).to('mps'), labels.view(-1).to('mps'))\n",
    "#     return loss\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    # ========== Training ==========\n",
    "    \n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Tracking variables\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    \n",
    "    # tqdm for progress bars\n",
    "    with tqdm(train_dataloader, unit=\"batch\") as tepoch:\n",
    "        for step, batch in enumerate(tepoch):\n",
    "            tepoch.set_description(f\"Epoch {epoch}\")\n",
    "\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            b_input_ids, b_input_mask, b_labels = batch\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            train_output = model(b_input_ids, \n",
    "                                token_type_ids = None, \n",
    "                                attention_mask = b_input_mask, \n",
    "                                labels = b_labels)\n",
    "            \n",
    "            # training_loss = compute_loss(train_output.logits, b_labels) # new loss\n",
    "\n",
    "            # Backward pass\n",
    "            train_output.loss.backward()\n",
    "            # training_loss.backward() # new loss\n",
    "\n",
    "            # # gradient clipping set to 5.0 in line with E. Savini Paper\n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "            optimizer.step()\n",
    "            # Update tracking variables\n",
    "            tr_loss += train_output.loss.item()\n",
    "            # tr_loss += training_loss.item() # new loss\n",
    "            nb_tr_examples += b_input_ids.size(0)\n",
    "            nb_tr_steps += 1\n",
    "\n",
    "        # --- VALIDATE -------------------------------------\n",
    "        val_loss, val_acc, val_f1, val_recall, val_precision = validate(model, validation_dataloader, device, val_loss_fn)\n",
    "        print('\\t - Train loss: {:.6f}'.format(tr_loss / nb_tr_steps))\n",
    "        print('\\t - Validation Loss: {:.6f}'.format(val_loss))\n",
    "        print('\\t - Validation Accuracy: {:.6f}'.format(val_acc))\n",
    "        print('\\t - Validation F1: {:.6f}'.format(val_f1))\n",
    "        print('\\t - Validation Recall: {:.6f}'.format(val_recall))\n",
    "        print('\\t - Validation Precision: {:.6f}'.format(val_precision))\n",
    "        # ----------- SAVE -----------\n",
    "        save_dir = \"model_saves/\"\n",
    "        model_name = \"bert_sarc_long_test\"\n",
    "        save_freq = 1\n",
    "        save_model(epoch, model, tokenizer, save_dir, model_name, save_freq, val_acc, val_f1)\n",
    "\n",
    "        # ----------- NOTIFY -----------\n",
    "        if notify == True:\n",
    "            phone_number = \"+573042084792\"\n",
    "            message = f\"{model_name} epoch {epoch}:\\nAccuracy: {round(val_acc, 2)} \\nF1: {round(val_f1, 2)}\"\n",
    "            send_message(phone_number, message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextClassificationPipeline\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "PATH = 'model_saves/bert_sarc_long_test/E04_A0.92_F0.91/'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(PATH, local_files_only=True)\n",
    "tokenizer = RobertaTokenizer.from_pretrained(PATH, local_files_only=True)\n",
    "\n",
    "# define pipeline\n",
    "pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/target_semEval2022_en/iSarcasmEval-main/test/task_A_En_test.csv')\n",
    "df = df.rename(columns={'tweet': 'text'})\n",
    "df = df.rename(columns={'sarcastic': 'label'})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = df['text'].to_list()\n",
    "\n",
    "test_output = []\n",
    "\n",
    "# run tests and append to output\n",
    "with tqdm(test_input, unit=\"test\") as prog:\n",
    "    for step, test in enumerate(prog):\n",
    "        prog.set_description(f\"Test {step}\")\n",
    "        test_output.append(pipe(test)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse predictions to new list\n",
    "predictions = []\n",
    "\n",
    "for i in test_output:\n",
    "    predictions.append(i[0]['label'])\n",
    "    \n",
    "print(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['preds'] = predictions\n",
    "df[\"preds\"] = df[\"preds\"].str.replace(\"LABEL_\",\"\")\n",
    "df['preds'] = df[\"preds\"].astype(int)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "# epoch 3\n",
    "acc = accuracy_score(df['label'], df['preds'])\n",
    "f1 = f1_score(df['label'], df['preds'])\n",
    "\n",
    "print(acc)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('itesd_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3c42b54925bdca82cdb5059acc0a21648e00763ff265e64872b54aa656b5d9d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
