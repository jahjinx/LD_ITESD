{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# intermediate_hellaswag\n",
    "This notebook takes our hellaswag dataset and trains an intermediate model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, update working directory to parent so that we may use our custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "# os.getcwd( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import params\n",
    "from utils import *\n",
    "from trainer import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_from_disk\n",
    "\n",
    "from transformers import RobertaTokenizer, RobertaForMultipleChoice\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "\n",
    "# suppress model warning\n",
    "from transformers import logging\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "# set logging level\n",
    "import logging\n",
    "logging.basicConfig(format='%(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're Armed: macOS-13.1-arm64-i386-64bit\n"
     ]
    }
   ],
   "source": [
    "# set general seeds\n",
    "set_seeds(1)\n",
    "\n",
    "# set dataloader generator seed\n",
    "g = torch.Generator()\n",
    "g.manual_seed(1)\n",
    "\n",
    "# set params for this model\n",
    "params.num_labels = 4\n",
    "params.output_dir = \"model_saves/intermediate_CosmosQA_01\"\n",
    "params.dataset_path = \"data/inter_cosmosqa/itesd_cosmosqa_balanced.hf\"\n",
    "\n",
    "# Ensure we're on an ARM environment if necessary.\n",
    "platform_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosmos QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmos_datasets = load_from_disk(params.dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'context', 'question', 'answer0', 'answer1', 'answer2', 'answer3', 'label'],\n",
       "        num_rows: 22272\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'context', 'question', 'answer0', 'answer1', 'answer2', 'answer3', 'label'],\n",
       "        num_rows: 2985\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'context', 'question', 'answer0', 'answer1', 'answer2', 'answer3', 'label'],\n",
       "        num_rows: 2825\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosmos_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: I had mentioned my call from Omaha in my previous entry and I finally got a hold of the HR lady who was trying to reach me . Like I had expected , it was far from a solid offer , rather just seeing if I was still interested in positions . Still it was the first real bite I ' ve gotten from the line I had sunk in that pond and its not like I have a whole lot of options , so I said I was still interested .\n",
      "Question: What happened after the call ?\n",
      "  A - I accepted the position .\n",
      "  B - I chose a different option .\n",
      "  C - I went fishing .\n",
      "  D - None of the above choices .\n",
      "\n",
      "Ground truth: option A\n"
     ]
    }
   ],
   "source": [
    "def show_one(example):\n",
    "    print(f\"Context: {example['context']}\")\n",
    "    print(f\"Question: {example['question']}\")\n",
    "    print(f\"  A - {example['answer0']}\")\n",
    "    print(f\"  B - {example['answer1']}\")\n",
    "    print(f\"  C - {example['answer2']}\")\n",
    "    print(f\"  D - {example['answer3']}\")\n",
    "    print(f\"\\nGround truth: option {['A', 'B', 'C', 'D'][example['label']]}\")\n",
    "\n",
    "show_one(cosmos_datasets[\"train\"][50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\", use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at data/inter_cosmosqa/itesd_cosmosqa_balanced.hf/train/cache-990048748da5baca.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00c752c20b7a4680ab85aaf30d41fa39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d88c5c029b50465f935f65659da35047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'context', 'question', 'answer0', 'answer1', 'answer2', 'answer3', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 22272\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'context', 'question', 'answer0', 'answer1', 'answer2', 'answer3', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2985\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'context', 'question', 'answer0', 'answer1', 'answer2', 'answer3', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2825\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoding_dict\n",
    "encoded_datasets = cosmos_datasets.map(mc_preprocessing, batched=True)\n",
    "\n",
    "encoded_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double-Check input_id lengths\n",
    "We're performing this check to ensure that 256 max token length is sufficient for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89088\n"
     ]
    }
   ],
   "source": [
    "train_ids = encoded_datasets[\"train\"]['input_ids']\n",
    "\n",
    "lengths = []\n",
    "for i in train_ids:\n",
    "    for j in i:\n",
    "        lengths.append(len(j))\n",
    "\n",
    "print(len(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[75, 75, 76, 77, 97, 98, 98, 100, 91, 94]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View input Structure\n",
    "\n",
    "The inputs are four copies of cxt_a and ctx_b each strung together with one ending option. They start with the \\<s> BOS token, which may act as the CLS token instead, and are separated with the \\</s> token--end of sequence or separator token.\n",
    "\n",
    "https://huggingface.co/docs/transformers/model_doc/roberta\n",
    "https://stackoverflow.com/questions/61465223/roberta-tokenization-of-multiple-sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: Beth managed to locate a small eatery that sold sandwiches . I headed over with Will and asked for one . At first , I did n't know what I was ordering ; I just pointed to what looked good . Turns out that I ordered a brie sandwich with lettuce , tomato , and butter .\n",
      "Question: What 's a possible reason Beth located an eatery ?\n",
      "  A - Because she was hungry .\n",
      "  B - None of the above choices .\n",
      "  C - Because the eatery sells sandwiches .\n",
      "  D - Because the writer did n't know what they were ordering .\n",
      "\n",
      "Ground truth: option A\n"
     ]
    }
   ],
   "source": [
    "show_one(cosmos_datasets[\"train\"][100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Beth managed to locate a small eatery that sold sandwiches. I headed over with Will and asked for one. At first, I didn't know what I was ordering ; I just pointed to what looked good. Turns out that I ordered a brie sandwich with lettuce, tomato, and butter.</s></s>What's a possible reason Beth located an eatery?</s></s>Because she was hungry.</s>\n",
      "<s>Beth managed to locate a small eatery that sold sandwiches. I headed over with Will and asked for one. At first, I didn't know what I was ordering ; I just pointed to what looked good. Turns out that I ordered a brie sandwich with lettuce, tomato, and butter.</s></s>What's a possible reason Beth located an eatery?</s></s>None of the above choices.</s>\n",
      "<s>Beth managed to locate a small eatery that sold sandwiches. I headed over with Will and asked for one. At first, I didn't know what I was ordering ; I just pointed to what looked good. Turns out that I ordered a brie sandwich with lettuce, tomato, and butter.</s></s>What's a possible reason Beth located an eatery?</s></s>Because the eatery sells sandwiches.</s>\n",
      "<s>Beth managed to locate a small eatery that sold sandwiches. I headed over with Will and asked for one. At first, I didn't know what I was ordering ; I just pointed to what looked good. Turns out that I ordered a brie sandwich with lettuce, tomato, and butter.</s></s>What's a possible reason Beth located an eatery?</s></s>Because the writer didn't know what they were ordering.</s>\n"
     ]
    }
   ],
   "source": [
    "print(params.tokenizer.decode(encoded_datasets['train'][\"input_ids\"][100][0]))\n",
    "print(params.tokenizer.decode(encoded_datasets['train'][\"input_ids\"][100][1]))\n",
    "print(params.tokenizer.decode(encoded_datasets['train'][\"input_ids\"][100][2]))\n",
    "print(params.tokenizer.decode(encoded_datasets['train'][\"input_ids\"][100][3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 387, 4774, 2312, 7, 12982, 10, 650, 19969, 219, 14, 1088, 19072, 479, 38, 3475, 81, 19, 2290, 8, 553, 13, 65, 479, 497, 78, 2156, 38, 222, 295, 75, 216, 99, 38, 21, 12926, 25606, 38, 95, 3273, 7, 99, 1415, 205, 479, 27271, 66, 14, 38, 2740, 10, 741, 3636, 15649, 19, 24515, 2156, 20406, 2156, 8, 9050, 479, 2, 2, 2264, 128, 29, 10, 678, 1219, 10472, 2034, 41, 19969, 219, 17487, 2, 2, 10105, 79, 21, 11130, 479, 2]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(encoded_datasets['train'][\"input_ids\"][100][0])\n",
    "print(encoded_datasets['train'][\"attention_mask\"][100][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect necessary features from encoded datasets and arrange them into a\n",
    "# a format acceptable by the dataloader\n",
    "train_features = construct_input(encoded_datasets['train'])\n",
    "validate_features = construct_input(encoded_datasets['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaders w collation\n",
    "# Prepare DataLoader\n",
    "train_dataloader = DataLoader(\n",
    "            train_features,\n",
    "            sampler = RandomSampler(train_features),\n",
    "            batch_size = params.batch_size,\n",
    "            worker_init_fn=seed_worker,\n",
    "            generator=g,\n",
    "            collate_fn=collate\n",
    "        )\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "            validate_features,\n",
    "            sampler = RandomSampler(validate_features),\n",
    "            batch_size = params.batch_size,\n",
    "            worker_init_fn=seed_worker,\n",
    "            generator=g,\n",
    "            collate_fn=collate\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[    0, 43725,   352,  ...,     1,     1,     1],\n",
       "          [    0, 43725,   352,  ...,     1,     1,     1],\n",
       "          [    0, 43725,   352,  ...,     1,     1,     1],\n",
       "          [    0, 43725,   352,  ...,     1,     1,     1]],\n",
       " \n",
       "         [[    0,   713,  3298,  ...,     1,     1,     1],\n",
       "          [    0,   713,  3298,  ...,     1,     1,     1],\n",
       "          [    0,   713,  3298,  ...,     1,     1,     1],\n",
       "          [    0,   713,  3298,  ...,     1,     1,     1]],\n",
       " \n",
       "         [[    0,   243,  2594,  ...,     1,     1,     1],\n",
       "          [    0,   243,  2594,  ...,     1,     1,     1],\n",
       "          [    0,   243,  2594,  ...,     1,     1,     1],\n",
       "          [    0,   243,  2594,  ...,     1,     1,     1]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[    0,   243,  2092,  ...,     1,     1,     1],\n",
       "          [    0,   243,  2092,  ...,     1,     1,     1],\n",
       "          [    0,   243,  2092,  ...,     1,     1,     1],\n",
       "          [    0,   243,  2092,  ...,     1,     1,     1]],\n",
       " \n",
       "         [[    0,   100,  9159,  ...,     1,     1,     1],\n",
       "          [    0,   100,  9159,  ...,     1,     1,     1],\n",
       "          [    0,   100,  9159,  ...,     1,     1,     1],\n",
       "          [    0,   100,  9159,  ...,     1,     1,     1]],\n",
       " \n",
       "         [[    0,   970,    21,  ...,     1,     1,     1],\n",
       "          [    0,   970,    21,  ...,     1,     1,     1],\n",
       "          [    0,   970,    21,  ...,     1,     1,     1],\n",
       "          [    0,   970,    21,  ...,     1,     1,     1]]]),\n",
       " tensor([[[1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0]]]),\n",
       " tensor([0, 2, 1, 1, 0, 2, 1, 2, 1, 0, 0, 0, 0, 0, 1, 1])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view an example from the dataloader\n",
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note: if continuing from checkpoint, continue to next section\n",
    "\n",
    "Download transformers.RobertaForSequenceClassification, which is a RoBERTa model with a linear layer for sentence classification (or regression) on top of the pooled output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type:depth-idx)                                       Output Shape              Param #\n",
       "==============================================================================================================\n",
       "RobertaForMultipleChoice                                     [1, 4]                    --\n",
       "├─RobertaModel: 1-1                                          [4, 768]                  --\n",
       "│    └─RobertaEmbeddings: 2-1                                [4, 256, 768]             --\n",
       "│    │    └─Embedding: 3-1                                   [4, 256, 768]             38,603,520\n",
       "│    │    └─Embedding: 3-2                                   [4, 256, 768]             768\n",
       "│    │    └─Embedding: 3-3                                   [4, 256, 768]             394,752\n",
       "│    │    └─LayerNorm: 3-4                                   [4, 256, 768]             1,536\n",
       "│    │    └─Dropout: 3-5                                     [4, 256, 768]             --\n",
       "│    └─RobertaEncoder: 2-2                                   [4, 256, 768]             --\n",
       "│    │    └─ModuleList: 3-6                                  --                        85,054,464\n",
       "│    └─RobertaPooler: 2-3                                    [4, 768]                  --\n",
       "│    │    └─Linear: 3-7                                      [4, 768]                  590,592\n",
       "│    │    └─Tanh: 3-8                                        [4, 768]                  --\n",
       "├─Dropout: 1-2                                               [4, 768]                  --\n",
       "├─Linear: 1-3                                                [4, 1]                    769\n",
       "==============================================================================================================\n",
       "Total params: 124,646,401\n",
       "Trainable params: 124,646,401\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 498.59\n",
       "==============================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 855.66\n",
       "Params size (MB): 498.59\n",
       "Estimated Total Size (MB): 1354.25\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the RobertaForSequenceClassification model\n",
    "model = RobertaForMultipleChoice.from_pretrained('roberta-base',\n",
    "                                                  num_labels = params.num_labels,\n",
    "                                                  output_attentions = False,\n",
    "                                                  output_hidden_states = False,\n",
    "                                                    )\n",
    "\n",
    "from torchinfo import summary\n",
    "summary(model, input_size=(1, 4, 256), dtypes=['torch.IntTensor'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set model to device, initialize trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n",
      "\n",
      "          Training Dataset: data/inter_cosmosqa/itesd_cosmosqa_balanced.hf\n",
      "          Number of Labels: 4\n",
      "          Batch Size: 16\n",
      "          Learning Rate: 1e-05\n",
      "          Weight Decay: 0\n",
      "          Epochs: 10\n",
      "          Output Directory: model_saves/intermediate_CosmosQA_01\n",
      "          Save Frequency: 1\n",
      "          Checkpoint Frequency: 1\n",
      "          Max Length: 256\n",
      "          \n"
     ]
    }
   ],
   "source": [
    "model.to(params.device)\n",
    "# print(f\"Trained Dataset: {dataset_path}\")\n",
    "print(f\"Device: {params.device}\")\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), \n",
    "                             lr=params.learning_rate,\n",
    "                             weight_decay=params.weight_decay) #roberta\n",
    "\n",
    "trainer = Trainer(model=model,\n",
    "                  device=params.device,\n",
    "                  tokenizer=params.tokenizer,\n",
    "                  train_dataloader=train_dataloader,\n",
    "                  validation_dataloader=validation_dataloader,\n",
    "                  epochs=params.epochs,\n",
    "                  optimizer=optimizer,\n",
    "                  val_loss_fn=params.val_loss_fn,\n",
    "                  num_labels=params.num_labels,\n",
    "                  output_dir=params.output_dir,\n",
    "                  save_freq=params.save_freq,\n",
    "                  checkpoint_freq=params.checkpoint_freq)\n",
    "\n",
    "output_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1392/1392 [1:30:00<00:00,  3.88s/batch]\n",
      "\t Validation 186: 100%|██████████| 187/187 [03:16<00:00,  1.05s/batch]\n",
      "\n",
      " \t - Train loss: 1.014240\n",
      "\t - Validation Loss: 0.935583\n",
      "\t - Validation Accuracy: 0.640523\n",
      "\t - Validation F1: 0.640523\n",
      "\t - Validation Recall: 0.640523\n",
      "\t - Validation Precision: 0.640523 \n",
      "\n",
      "\t * Model @ epoch 1 saved to model_saves/intermediate_CosmosQA_01/E01_A0.64_F0.64\n",
      "\t * Model checkpoint saved to model_saves/intermediate_CosmosQA_01/E01_A0.64_F0.64/checkpoint.pt\n",
      "\n",
      "Epoch 2:   0%|          | 1/1392 [00:03<1:31:10,  3.93s/batch]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/LD_ITESD_balanced/trainer.py:130\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m    129\u001b[0m \u001b[39m# Forward pass\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m train_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(b_input_ids, \n\u001b[1;32m    131\u001b[0m                     token_type_ids \u001b[39m=\u001b[39;49m \u001b[39mNone\u001b[39;49;00m, \n\u001b[1;32m    132\u001b[0m                     attention_mask \u001b[39m=\u001b[39;49m b_input_mask, \n\u001b[1;32m    133\u001b[0m                     labels \u001b[39m=\u001b[39;49m b_labels)\n\u001b[1;32m    135\u001b[0m \u001b[39m# training_loss = compute_loss(train_output.logits, b_labels) # custom loss\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \n\u001b[1;32m    137\u001b[0m \u001b[39m# Backward pass\u001b[39;00m\n\u001b[1;32m    138\u001b[0m train_output\u001b[39m.\u001b[39mloss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/itesd_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1423\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1421\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1422\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1423\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1424\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/itesd_env/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:1310\u001b[0m, in \u001b[0;36mRobertaForMultipleChoice.forward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, labels, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1303\u001b[0m flat_attention_mask \u001b[39m=\u001b[39m attention_mask\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, attention_mask\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)) \u001b[39mif\u001b[39;00m attention_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1304\u001b[0m flat_inputs_embeds \u001b[39m=\u001b[39m (\n\u001b[1;32m   1305\u001b[0m     inputs_embeds\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, inputs_embeds\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m), inputs_embeds\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m   1306\u001b[0m     \u001b[39mif\u001b[39;00m inputs_embeds \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1307\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1308\u001b[0m )\n\u001b[0;32m-> 1310\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroberta(\n\u001b[1;32m   1311\u001b[0m     flat_input_ids,\n\u001b[1;32m   1312\u001b[0m     position_ids\u001b[39m=\u001b[39;49mflat_position_ids,\n\u001b[1;32m   1313\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mflat_token_type_ids,\n\u001b[1;32m   1314\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mflat_attention_mask,\n\u001b[1;32m   1315\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1316\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49mflat_inputs_embeds,\n\u001b[1;32m   1317\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1318\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1319\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1320\u001b[0m )\n\u001b[1;32m   1321\u001b[0m pooled_output \u001b[39m=\u001b[39m outputs[\u001b[39m1\u001b[39m]\n\u001b[1;32m   1323\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/itesd_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1423\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1421\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1422\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1423\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1424\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/itesd_env/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:844\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    835\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    837\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m    838\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m    839\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    842\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    843\u001b[0m )\n\u001b[0;32m--> 844\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m    845\u001b[0m     embedding_output,\n\u001b[1;32m    846\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m    847\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    848\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    849\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m    850\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m    851\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    852\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    853\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    854\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    855\u001b[0m )\n\u001b[1;32m    856\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    857\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/itesd_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1423\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1421\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1422\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1423\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1424\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/itesd_env/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:520\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    511\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    512\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    513\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    517\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    518\u001b[0m     )\n\u001b[1;32m    519\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 520\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    521\u001b[0m         hidden_states,\n\u001b[1;32m    522\u001b[0m         attention_mask,\n\u001b[1;32m    523\u001b[0m         layer_head_mask,\n\u001b[1;32m    524\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    525\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    526\u001b[0m         past_key_value,\n\u001b[1;32m    527\u001b[0m         output_attentions,\n\u001b[1;32m    528\u001b[0m     )\n\u001b[1;32m    530\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    531\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/itesd_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1423\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1421\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1422\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1423\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1424\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/itesd_env/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:447\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    444\u001b[0m     cross_attn_present_key_value \u001b[39m=\u001b[39m cross_attention_outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    445\u001b[0m     present_key_value \u001b[39m=\u001b[39m present_key_value \u001b[39m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 447\u001b[0m layer_output \u001b[39m=\u001b[39m apply_chunking_to_forward(\n\u001b[1;32m    448\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeed_forward_chunk, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunk_size_feed_forward, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseq_len_dim, attention_output\n\u001b[1;32m    449\u001b[0m )\n\u001b[1;32m    450\u001b[0m outputs \u001b[39m=\u001b[39m (layer_output,) \u001b[39m+\u001b[39m outputs\n\u001b[1;32m    452\u001b[0m \u001b[39m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/itesd_env/lib/python3.9/site-packages/transformers/pytorch_utils.py:246\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[39m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(output_chunks, dim\u001b[39m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 246\u001b[0m \u001b[39mreturn\u001b[39;00m forward_fn(\u001b[39m*\u001b[39;49minput_tensors)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/itesd_env/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:460\u001b[0m, in \u001b[0;36mRobertaLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeed_forward_chunk\u001b[39m(\u001b[39mself\u001b[39m, attention_output):\n\u001b[1;32m    459\u001b[0m     intermediate_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate(attention_output)\n\u001b[0;32m--> 460\u001b[0m     layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput(intermediate_output, attention_output)\n\u001b[1;32m    461\u001b[0m     \u001b[39mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/itesd_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1423\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1421\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1422\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1423\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1424\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/itesd_env/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:372\u001b[0m, in \u001b[0;36mRobertaOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states: torch\u001b[39m.\u001b[39mTensor, input_tensor: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m    371\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdense(hidden_states)\n\u001b[0;32m--> 372\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout(hidden_states)\n\u001b[1;32m    373\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(hidden_states \u001b[39m+\u001b[39m input_tensor)\n\u001b[1;32m    374\u001b[0m     \u001b[39mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/itesd_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1423\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1421\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1422\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1423\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1424\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/itesd_env/lib/python3.9/site-packages/torch/nn/modules/dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mp, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/itesd_env/lib/python3.9/site-packages/torch/nn/functional.py:1252\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[39mif\u001b[39;00m p \u001b[39m<\u001b[39m \u001b[39m0.0\u001b[39m \u001b[39mor\u001b[39;00m p \u001b[39m>\u001b[39m \u001b[39m1.0\u001b[39m:\n\u001b[1;32m   1251\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdropout probability has to be between 0 and 1, \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(p))\n\u001b[0;32m-> 1252\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39mdropout_(\u001b[39minput\u001b[39m, p, training) \u001b[39mif\u001b[39;00m inplace \u001b[39melse\u001b[39;00m _VF\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39;49m, p, training)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue Training from Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the RobertaForSequenceClassification model\n",
    "model = RobertaForMultipleChoice.from_pretrained('roberta-base',\n",
    "                                                  num_labels = params.num_labels,\n",
    "                                                  output_attentions = False,\n",
    "                                                  output_hidden_states = False,\n",
    "                                                    )\n",
    "\n",
    "model.to(params.device)\n",
    "print(f\"Device: {params.device}\")\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=params.learning_rate) #roberta\n",
    "\n",
    "checkpoint_load = \"model_saves/intermediate_cosmos_01/E07_A0.68_F0.68/checkpoint.pt\"\n",
    "\n",
    "trainer = Trainer(model=model,\n",
    "                  device=params.device,\n",
    "                  tokenizer=params.tokenizer,\n",
    "                  train_dataloader=train_dataloader,\n",
    "                  validation_dataloader=validation_dataloader,\n",
    "                  epochs=params.epochs,\n",
    "                  optimizer=optimizer,\n",
    "                  val_loss_fn=params.val_loss_fn,\n",
    "                  num_labels=params.num_labels,\n",
    "                  output_dir=params.output_dir,\n",
    "                  save_freq=params.save_freq,\n",
    "                  checkpoint_freq=params.checkpoint_freq, \n",
    "                  checkpoint_load=checkpoint_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('itesd_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3c42b54925bdca82cdb5059acc0a21648e00763ff265e64872b54aa656b5d9d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
